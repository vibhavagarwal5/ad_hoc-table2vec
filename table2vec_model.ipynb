{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Progress bar is an experimental feature. This can lead to a considerable performance loss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8e349d4da94562b4b3b8df57674f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New pandarallel memory created - Size: 2500 MB\n",
      "Pandarallel will run on 15 workers\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True,nb_workers=15,shm_size_mb=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_f = pd.read_csv('./www2018-table/feature/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_f_ = pd.read_csv('./semantic_f_w2v_g2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bf = ['row', 'col', 'nul', 'in_link', 'out_link', 'pgcount', 'tImp', 'tPF', 'leftColhits', 'SecColhits', 'bodyhits', 'PMI', 'qInPgTitle', 'qInTableTitle', 'yRank', 'csr_score', 'idf1', 'idf2', 'idf3', 'idf4', 'idf5', 'idf6', 'max', 'sum', 'avg', 'sim', 'emax', 'esum', 'eavg', 'esim', 'cmax', 'csum', 'cavg', 'csim', 'remax', 'resum', 'reavg', 'resim', 'query_l']\n",
    "x_smf_w = ['w2v_early_fusion', 'w2v_late_fusion_max', 'w2v_late_fusion_avg', 'w2v_late_fusion_sum']\n",
    "x_smf_g = ['g2v_early_fusion', 'g2v_late_fusion_max', 'g2v_late_fusion_avg', 'g2v_late_fusion_sum']\n",
    "x_smf = x_smf_w\n",
    "y_f = ['rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseline_f[x_bf]\n",
    "X = pd.concat([baseline_f[x_bf],semantic_f_[x_smf]],axis=1)\n",
    "y = baseline_f[y_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('./www2018-table/rankings/LTR.txt', sep=\"\\t\",header=None)\n",
    "d1.drop(columns=[1,3,4,5],inplace=True)\n",
    "\n",
    "l1 = [(row._1,row._2) for row in d1.itertuples()]\n",
    "ltr_in = []\n",
    "for row in baseline_f.itertuples():\n",
    "    if (row.query_id,row.table_id) in l1:\n",
    "        ltr_in.append(row.Index)\n",
    "anti_ltr_in = list(set(baseline_f.index.tolist()) - set(ltr_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/vibhav/bar/virtualenv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# kfold = KFold(5, True, 42)\n",
    "# for i, indices in enumerate(kfold.split(X_train)):\n",
    "#     train, test = indices\n",
    "#     X_train1, y_train1 = X_train.iloc[train], y_train.iloc[train]\n",
    "#     clf.fit(X_train1, y_train1)\n",
    "    \n",
    "# X_test = generateScore(X_test)\n",
    "# df = generate_sorted_df(X_test,y_test)\n",
    "# df1 = generate_trec_df(df)\n",
    "# df1.to_csv('./Results/LTR_tr80_5fld_tr20.txt', sep=' ', index=False, header=False)\n",
    "\n",
    "kfold = KFold(5, True, 42)\n",
    "for i, indices in enumerate(kfold.split(X)):\n",
    "    train, test = indices\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test]\n",
    "    df1 = makeModel_getdf(X_train, X_test, y_train, y_test)\n",
    "    df1.to_csv('./Results/LTR_w_k5_diff_{}.txt'.format(i), sep=' ', index=False, header=False)\n",
    "    \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# X_test = pd.DataFrame()\n",
    "# for i in range(1,61):\n",
    "#     X_test = pd.concat([X_test,baseline_f[baseline_f.query_id==i][x_bf].sample(20)])\n",
    "# y_test = baseline_f.iloc[X_test.index.values][y_f]\n",
    "# y_train = baseline_f.iloc[list(set(baseline_f.index.values) - set(X_test.index.values))][y_f]\n",
    "# X_train = baseline_f.iloc[list(set(baseline_f.index.values) - set(X_test.index.values))][x_bf]\n",
    "\n",
    "# X_train = X.iloc[anti_ltr_in]\n",
    "# X_test = X.iloc[ltr_in]\n",
    "# y_train = y.iloc[anti_ltr_in]\n",
    "# y_test = y.iloc[ltr_in]\n",
    "\n",
    "# df1 = makeModel_getdf(X_train, X_test, y_train, y_test)\n",
    "# df1.to_csv('./Results/test.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./trec_eval/trec_eval -m ndcg_cut.5,10,15,20 ./Results/qrels.txt ./Results/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel_getdf(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=3,max_features=3,random_state=42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    X_test['model_score'] = X_test.parallel_apply(lambda x: getScore(x,clf),axis=1)\n",
    "    df = generate_sorted_df(X_test,y_test)\n",
    "    df1 = generate_trec_df(df)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(row,clf):\n",
    "    arr = clf.predict_proba(np.array(row).reshape(1,-1))\n",
    "    return arr[0][1]+2*arr[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_sorted_df(X,y):\n",
    "#     df_temp = pd.concat([\n",
    "#         X[['model_score']],\n",
    "#         y],axis=1)\n",
    "    df_temp = pd.concat([\n",
    "        baseline_f.iloc[list(X.index)][['query_id', 'query', 'table_id']],\n",
    "        X['model_score']],axis=1)\n",
    "\n",
    "#     df_sorted = df_temp.sort_values(by=['query_id', 'model_score'], ascending=[True,False])\n",
    "\n",
    "#     df1 = pd.DataFrame()\n",
    "#     for i in range(1,61):\n",
    "# #         print(i,df_sorted[df_sorted.query_id == i][:20].shape)\n",
    "#         df1 = pd.concat([df1,df_sorted[df_sorted.query_id == i][:20]])\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trec_df(df1):\n",
    "    l = []\n",
    "    dic = dict(df1.query_id.value_counts())\n",
    "    for i in dic:\n",
    "        for j in range(1,dic[i]+1):\n",
    "            l.append(j)\n",
    "#     for i in range(60):\n",
    "#         for j in range(1,21):\n",
    "#             l.append(j)\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['query_id'] = df1['query_id']\n",
    "    df2['Q0'] = 'Q0'\n",
    "    df2['table_id'] = df1['table_id']\n",
    "    df2['rank'] = l\n",
    "    df2['score'] = df1['model_score']\n",
    "    df2['smarttable'] = 'smarttable'\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
